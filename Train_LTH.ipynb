{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO DO: Find and set the reward function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/etrrhmd/anaconda3/envs/wasp_summer_2020/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/Users/etrrhmd/anaconda3/envs/wasp_summer_2020/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/etrrhmd/anaconda3/envs/wasp_summer_2020/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/etrrhmd/anaconda3/envs/wasp_summer_2020/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/etrrhmd/anaconda3/envs/wasp_summer_2020/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/etrrhmd/anaconda3/envs/wasp_summer_2020/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/etrrhmd/anaconda3/envs/wasp_summer_2020/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# Simple env test.\n",
    "import json\n",
    "import select\n",
    "import time\n",
    "import logging\n",
    "import os\n",
    "\n",
    "import gym\n",
    "#import snake_gym\n",
    "import minerl\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from collections import deque\n",
    "\n",
    "#from minerl.herobraine.hero import spaces\n",
    "#from minerl.herobraine.env_spec import MISSIONS_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"MineRLNavigateDense-v0\", xml=\"lth_navigation.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''env = gym.make(\"MineRLNavigateDense-v0\", xml=\"lth_navigation.xml\",  \n",
    "               observation_space=spaces.Dict({'pov': spaces.Box(low=0, high=255, shape=(64, 64, 3), dtype=np.uint8),}),\n",
    "               action_space = spaces.Dict(spaces={\"forward\": spaces.Discrete(2),\n",
    "                                                  \"back\": spaces.Discrete(2),\n",
    "                                                  \"left\": spaces.Discrete(2), \n",
    "                                                  \"right\": spaces.Discrete(2), \n",
    "                                                  \"jump\": spaces.Discrete(2), \n",
    "                                                  \"sneak\": spaces.Discrete(2), \n",
    "                                                  \"sprint\": spaces.Discrete(2), \n",
    "                                                  \"attack\": spaces.Discrete(2),\n",
    "                                                  \"camera\": spaces.Box(low=-180, high=180, shape=(2,), dtype=np.float32),})\n",
    "              )'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('compassAngle', array(15.3694)),\n",
       "             ('inventory', OrderedDict([('dirt', array(0))])),\n",
       "             ('pov',\n",
       "              array([[[ 93,  73,  68],\n",
       "                      [ 93,  53,  42],\n",
       "                      [ 87,  68,  63],\n",
       "                      ...,\n",
       "                      [  2,   2,   4],\n",
       "                      [107,  77,  85],\n",
       "                      [101,  65,  71]],\n",
       "              \n",
       "                     [[ 98,  82,  78],\n",
       "                      [ 93,  53,  42],\n",
       "                      [ 93,  53,  43],\n",
       "                      ...,\n",
       "                      [107,  76,  84],\n",
       "                      [103,  75,  84],\n",
       "                      [100,  74,  84]],\n",
       "              \n",
       "                     [[ 83,  47,  37],\n",
       "                      [ 98,  82,  78],\n",
       "                      [ 92,  68,  62],\n",
       "                      ...,\n",
       "                      [101,  65,  71],\n",
       "                      [101,  74,  85],\n",
       "                      [ 96,  63,  70]],\n",
       "              \n",
       "                     ...,\n",
       "              \n",
       "                     [[ 88,  88, 115],\n",
       "                      [104, 104, 137],\n",
       "                      [104, 104, 137],\n",
       "                      ...,\n",
       "                      [ 88,  87, 115],\n",
       "                      [ 94,  94, 124],\n",
       "                      [106, 105, 139]],\n",
       "              \n",
       "                     [[106, 106, 139],\n",
       "                      [106, 106, 139],\n",
       "                      [ 87,  87, 115],\n",
       "                      ...,\n",
       "                      [ 87,  87, 115],\n",
       "                      [ 87,  87, 115],\n",
       "                      [ 95,  95, 125]],\n",
       "              \n",
       "                     [[ 87,  87, 115],\n",
       "                      [ 87,  87, 115],\n",
       "                      [ 87,  87, 115],\n",
       "                      ...,\n",
       "                      [ 87,  87, 115],\n",
       "                      [ 87,  87, 115],\n",
       "                      [ 87,  87, 115]]], dtype=uint8))])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check what world is loaded\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dqn_network():\n",
    "    def __init__(self):\n",
    "        self.state = tf.placeholder(shape=[None,64,64,4], dtype=tf.float32)\n",
    "        self.conv1 = tf.layers.conv2d(inputs=self.state, filters=32, kernel_size=[8,8], strides=[4,4], \n",
    "                                      padding='VALID', activation=tf.nn.relu,\n",
    "                                      kernel_initializer=tf.contrib.layers.xavier_initializer(uniform=False),\n",
    "                                      kernel_regularizer=tf.contrib.layers.l2_regularizer(scale=10e-5),\n",
    "                                      bias_regularizer=tf.contrib.layers.l2_regularizer(scale=10e-5))\n",
    "        self.conv2 = tf.layers.conv2d(inputs=self.conv1, filters=64, kernel_size=[4,4], strides=[2,2], \n",
    "                                      padding='VALID', activation=tf.nn.relu,\n",
    "                                      kernel_initializer=tf.contrib.layers.xavier_initializer(uniform=False),\n",
    "                                      kernel_regularizer=tf.contrib.layers.l2_regularizer(scale=10e-5),\n",
    "                                      bias_regularizer=tf.contrib.layers.l2_regularizer(scale=10e-5))\n",
    "        self.conv3 = tf.layers.conv2d(inputs=self.conv2, filters=64, kernel_size=[3,3], strides=[1,1], \n",
    "                                      padding='VALID', activation=tf.nn.relu,\n",
    "                                      kernel_initializer=tf.contrib.layers.xavier_initializer(uniform=False),\n",
    "                                      kernel_regularizer=tf.contrib.layers.l2_regularizer(scale=10e-5),\n",
    "                                      bias_regularizer=tf.contrib.layers.l2_regularizer(scale=10e-5))\n",
    "        self.flat = tf.layers.flatten(self.conv3)\n",
    "        self.out = tf.layers.dense(self.flat, 3, activation=tf.nn.softmax)\n",
    "        self.predict = tf.argmax(self.out, 1)\n",
    "\n",
    "        self.action = tf.placeholder(shape=[None], dtype=tf.int32)\n",
    "        self.actions_onehot = tf.one_hot(self.action, 3, dtype=tf.float32)\n",
    "        self.Q = tf.reduce_sum(tf.multiply(self.out, self.actions_onehot), axis=1)\n",
    "\n",
    "        self.targetQ = tf.placeholder(shape=[None], dtype=tf.float32)\n",
    "        self.td_error = tf.square(self.targetQ - self.Q)\n",
    "            \n",
    "        self.loss = tf.reduce_mean(self.td_error)\n",
    "        self.train_step = tf.train.AdamOptimizer(0.001).minimize(self.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def converter(observation):\n",
    "    region_size = 8\n",
    "    obs = observation['pov']\n",
    "    obs = obs / 255\n",
    "    compass_angle = observation['compassAngle']\n",
    "\n",
    "    compass_angle_scale = 180\n",
    "    compass_scaled = compass_angle / compass_angle_scale\n",
    "    compass_channel = np.ones(shape=list(obs.shape[:-1]) + [1], dtype=obs.dtype) * compass_scaled\n",
    "    obs = np.concatenate([obs, compass_channel], axis=-1)\n",
    "\n",
    "    return obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-4-ffa615ac0b24>:8: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.conv2d instead.\n",
      "WARNING:tensorflow:From /Users/etrrhmd/anaconda3/envs/wasp_summer_2020/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From <ipython-input-4-ffa615ac0b24>:19: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From <ipython-input-4-ffa615ac0b24>:20: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From /Users/etrrhmd/anaconda3/envs/wasp_summer_2020/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "annealing_episodes = 100\n",
    "startE = 1.0\n",
    "endE = 0.1\n",
    "e = startE\n",
    "stepDrop = (startE - endE) / annealing_episodes\n",
    "\n",
    "network = dqn_network()\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "variables = tf.trainable_variables(scope=None)\n",
    "saver = tf.train.Saver(variables, max_to_keep=5)\n",
    "\n",
    "model_path = '/Users/etrrhmd/Documents/Code/wasp_summer_2020/reference/tf_model3'\n",
    "ckpt = tf.train.get_checkpoint_state(model_path)\n",
    "#saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "\n",
    "episodeBuffer = deque()\n",
    "total_steps = 0\n",
    "rList = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/etrrhmd/anaconda3/envs/wasp_summer_2020/lib/python3.7/site-packages/tensorflow/python/training/saver.py:966: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "rAll: 0.0\n",
      "rAll: 0.0\n",
      "rAll: 0.0\n",
      "rAll: 0.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-14a90d0a8445>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0maction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attack'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mobs1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0ms1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/wasp_summer_2020/lib/python3.7/site-packages/gym/wrappers/time_limit.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Cannot call env.step() before calling reset()\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_max_episode_steps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/wasp_summer_2020/lib/python3.7/site-packages/minerl/env/core.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m                 \u001b[0;31m# Receive the observation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 623\u001b[0;31m                 \u001b[0mobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient_socket\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m                 \u001b[0;31m# Receive reward done and sent.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/wasp_summer_2020/lib/python3.7/site-packages/minerl/env/comms.py\u001b[0m in \u001b[0;36mrecv_message\u001b[0;34m(sock)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrecv_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0mlengthbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecvall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlengthbuf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/wasp_summer_2020/lib/python3.7/site-packages/minerl/env/comms.py\u001b[0m in \u001b[0;36mrecvall\u001b[0;34m(sock, count)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mb''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0mnewbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnewbuf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(annealing_episodes):\n",
    "    # Reset environment and get first new observation\n",
    "    obs = env.reset()\n",
    "    s = converter(obs)\n",
    "\n",
    "    d = False\n",
    "    rAll = 0\n",
    "    steps = 0\n",
    "\n",
    "    if e > endE:\n",
    "        e -= stepDrop\n",
    "\n",
    "    # The Q-Network\n",
    "    while True: # If the agent takes longer than 200 moves to reach either of the blocks, end the trial.\n",
    "        #env.render()\n",
    "        #time.sleep(0.5)\n",
    "        steps += 1\n",
    "        total_steps += 1\n",
    "\n",
    "        # Choose an action by greedily (with e chance of random action) from the Q-network\n",
    "        if np.random.rand(1) < e:\n",
    "            action_index = np.random.randint(0,3)\n",
    "        else:\n",
    "            action_index = sess.run(network.predict, feed_dict={network.state:[s]})[0]\n",
    "\n",
    "        #print(\"action_index: \" + str(action_index))\n",
    "\n",
    "        action = env.action_space.noop()\n",
    "        if (action_index == 0):\n",
    "            action['camera'] = [0, -5]\n",
    "        elif (action_index == 1):\n",
    "            action['camera'] = [0, 5]\n",
    "        elif (action_index == 2):\n",
    "            action['forward'] = 1\n",
    "\n",
    "        action['jump'] = 1\n",
    "        action['attack'] = 1\n",
    "\n",
    "        obs1, r, d, _ = env.step(action)\n",
    "        s1 = converter(obs1)\n",
    "\n",
    "        episodeBuffer.append((s,action_index,r,s1,d))\n",
    "        if len(episodeBuffer) > 50000:\n",
    "            episodeBuffer.popleft()\n",
    "\n",
    "        if total_steps % 500 == 0:\n",
    "            saver.save(sess, model_path + '/model-' + str(total_steps) + '.cptk')\n",
    "\n",
    "        batch_size = 512\n",
    "        if total_steps % (batch_size) == 0:\n",
    "            trainBatch = random.sample(episodeBuffer, batch_size)\n",
    "\n",
    "            s_batch = [d[0] for d in trainBatch]\n",
    "            a_batch = [d[1] for d in trainBatch]\n",
    "            d_batch = [d[4] for d in trainBatch]\n",
    "            d_batch = (np.array(d_batch)).astype(int)\n",
    "\n",
    "            r_batch = [d[2] for d in trainBatch]\n",
    "            s1_batch = [d[3] for d in trainBatch]\n",
    "\n",
    "            #allQ = sess.run(network.Q, feed_dict={network.state:[trainBatch[:,0]]})\n",
    "            Q1 = sess.run(network.out, feed_dict={network.state:s1_batch})\n",
    "            end_multiplier = -(d_batch - 1)\n",
    "            targetQ = r_batch + 0.99 * np.max(Q1, axis=1) * end_multiplier\n",
    "\n",
    "            #print(\"train network\")\n",
    "            _ = sess.run(network.train_step, feed_dict={network.state:s_batch, \n",
    "                                                        network.targetQ:targetQ,\n",
    "                                                        network.action:a_batch})\n",
    "\n",
    "\n",
    "        rAll += r\n",
    "        s = s1\n",
    "\n",
    "\n",
    "        if d == True:\n",
    "            break\n",
    "\n",
    "    #jList.append(j)\n",
    "    print(\"rAll: \" + str(rAll))\n",
    "    rList.append(rAll)\n",
    "\n",
    "    if len(rList) % 10 == 0:\n",
    "        print(i, np.mean(rList[-10:]), e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to close the java/graddleStart window\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
